{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis points won\n",
    "\n",
    "In the `tennis.csv` files of games played by Federer.\n",
    "\n",
    "Does Federer score more total points than his opponent on average in a game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "On average, Federer scores less total points than his opponent in a game\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\David\\Documents\\code\\Module 2\\m2-1-pandas\\data\\tennis.csv')\n",
    "\n",
    "if df['player1 total points total'].mean() > df['player2 total points total'].mean():\n",
    "    print('On average, Federer scores more total points than his opponent in a game')\n",
    "else:\n",
    "    print('On average, Federer scores less total points than his opponent in a game')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. College correlations\n",
    "\n",
    "The `college.csv` filecontains a number of variables for 777 different universities and colleges in the US.\n",
    "\n",
    "### 2.1\n",
    "\n",
    "Use a scatterplot matrix to analyze the data and answer the following questions:\n",
    "\n",
    "1. Which columns are possibly from a normal distribution? Statistically test if this is the case (you'll find a function for it in `scipy.stats`). For each explain if it is or not normally distributed.\n",
    "\n",
    "2. Of the columns that aren't normally distributed, name which distribution could possibly fit them? (Use your research skills)\n",
    "\n",
    "3. Give 3 pairs of columns that are highly correlated? Give their correlation coefficients.\n",
    "\n",
    "4. Give 3 column pairs that are not correlated? Give their correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Apps is not normally distributed\nAccept is not normally distributed\nEnroll is not normally distributed\nTop10perc is not normally distributed\nTop25perc is not normally distributed\nF.Undergrad is not normally distributed\nP.Undergrad is not normally distributed\nOutstate is not normally distributed\nRoom.Board is not normally distributed\nBooks is not normally distributed\nPersonal is not normally distributed\nPhD is not normally distributed\nTerminal is not normally distributed\nS.F.Ratio is not normally distributed\nperc.alumni is not normally distributed\nExpend is not normally distributed\nGrad.Rate is normally distributed\nAccept         0.943451\nEnroll         0.846822\nF.Undergrad    0.814491\nName: Apps, dtype: float64\nperc.alumni   -0.090226\nOutstate       0.050159\nS.F.Ratio      0.095633\nName: Apps, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "#First, let's get the data set up.\n",
    "df = pd.read_csv(r'C:\\Users\\David\\Documents\\code\\Module 2\\m2-4-stats\\data\\college.csv')\n",
    "df = df.rename(columns= {'Unnamed: 0': 'Name'})\n",
    "\n",
    "#This dataframe has so many columns, we need to break it down into smaller plots\n",
    "# df_1 = df[['Name', 'Apps', 'Accept', 'Enroll', 'Top10perc', 'Top25perc', 'Private']]\n",
    "# df_2 = df[['F.Undergrad', 'P.Undergrad', 'Outstate', 'Room.Board', 'Books', 'Private']]\n",
    "# df_3 = df[['Personal', 'PhD', 'Terminal', 'S.F.Ratio', 'Private']]\n",
    "# df_4 = df[['perc.alumni', 'Expend', 'Grad.Rate', 'Private']]\n",
    "# sns.pairplot(df_1, hue='Private')\n",
    "# sns.pairplot(df_2, hue='Private')\n",
    "# sns.pairplot(df_3, hue='Private')\n",
    "# sns.pairplot(df_4, hue='Private')\n",
    "\n",
    "#At a first glance, the Top25Percent, GradRate, and Books appear to be normally distributed. Let's verify all the columns with a quick test.\n",
    "\n",
    "for thing in df:\n",
    "    if thing == 'Name' or thing == 'Private':\n",
    "        pass\n",
    "    else:\n",
    "        if sc.stats.normaltest(df[thing]).pvalue.astype(float) > 0.05:\n",
    "            print(thing, 'is normally distributed')\n",
    "        else:\n",
    "            print(thing, 'is not normally distributed')\n",
    "\n",
    "#Wow, it appears that GradRate is the only normal distribution.\n",
    "\n",
    "\n",
    "#Now let's test for correlation. Because I can see that there are many high distributions, I will simply return the three most related to Apps.\n",
    "yescorr_df = df.corr()['Apps'].nlargest(4)\n",
    "print(yescorr_df.drop('Apps'))\n",
    "\n",
    "# #now the least correlated variables.\n",
    "nocorr_df = df.corr()['Apps'].nsmallest(3)\n",
    "print(nocorr_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Boxplot\n",
    "\n",
    "Make a boxplot of private vs outstate colleges. It should look like:\n",
    "\n",
    "![](boxplort.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[['Outstate', 'Private']]\n",
    "sns.boxplot(y= df_.Outstate, x=df_.Private)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Auto data\n",
    "\n",
    "The `auto.csv` data file is malformed.\n",
    "\n",
    "Fix it (using only python) so that it can be read into pandas, and then give a scatterplot matrix of horsepower, weight, year and mpg.\n",
    "\n",
    "Did cars get more efficient over time? Make an argument on this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\David\\Documents\\code\\Module 2\\m2-4-stats\\data\\auto.csv')\n",
    "columns_ = df.columns.str.split()\n",
    "\n",
    "df = df.rename(columns={'mpg\\tcylinders\\tdisplacement\\thorsepower weight\\tacceleration\\tyear\\torigin\\tname': 1})\n",
    "df = df.drop([0])\n",
    "\n",
    "hold = pd.DataFrame()\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(0, len(columns_[0])):\n",
    "    df[1] = df[1].str.replace(\"   \", ' ')\n",
    "    df[1] = df[1].str.replace(\"  \", ' ')\n",
    "    df[1] = df[1].str.replace( '1\\t\"', ' ')\n",
    "    df[1] = df[1].str.replace( '2\\t\"', ' ')\n",
    "    df[1] = df[1].str.replace( '3\\t\"', ' ')\n",
    "    df[1] = df[1].str.replace( '?', '')\n",
    "    df = df[1].str.split(\" \", n = 1, expand = True) \n",
    "    hold[counter] = df[0]\n",
    "    df = df.drop([0], axis=1)\n",
    "\n",
    "    if counter <= 5:\n",
    "        hold[counter] = hold[counter].astype(float)\n",
    "    counter += 1\n",
    "\n",
    "df = pd.DataFrame(data=hold)\n",
    "\n",
    "df = df.rename(columns= {0: 'mpg' ,1:'cylinders',2:'displacement',3:'horsepower',4:'weight',5:'acceleration',6:'year',7:'origin',8:'name'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Auto Statistics\n",
    "\n",
    "What is the mean, median and standard deviation of each quantitative feature?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mpg mean: 24.40931677018633 median: 23.9 standard deviation: 7.913357147165568\ncylinders mean: 5.37888198757764 median: 4.0 standard deviation: 1.6573976500687335\ndisplacement mean: 187.6801242236025 median: 145.5 standard deviation: 100.12092459330134\nhorsepower mean: 130.83229813664596 median: 92.0 standard deviation: 271.24223832356364\nweight mean: 2906.1534161490686 median: 2789.5 standard deviation: 870.6753332637979\nacceleration mean: 16.478881987577633 median: 15.55 standard deviation: 7.505274655588004\n"
     ]
    }
   ],
   "source": [
    "colies = df.columns\n",
    "colies = colies.drop(['origin', 'year', 'name'])\n",
    "\n",
    "for col in colies:\n",
    "    print(col, 'mean:', df[col].mean(), 'median:', df[col].median(), 'standard deviation:', df[col].std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 data removal\n",
    "\n",
    "Remove the 10th through 85th observations. \n",
    "\n",
    "Does the mean statistically significantly change for each of the columns?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mpg mean: 26.05182186234817 median: 25.5 standard deviation: 7.730337417346293\ncylinders mean: 5.178137651821863 median: 4.0 standard deviation: 1.574907331536105\ndisplacement mean: 174.60323886639677 median: 140.0 standard deviation: 91.24792273855465\nhorsepower mean: 123.99595141700405 median: 90.0 standard deviation: 254.41288217715834\nweight mean: 2804.0421052631586 median: 2711.0 standard deviation: 779.7149436962154\nacceleration mean: 16.65263157894737 median: 15.8 standard deviation: 7.57946943181244\n"
     ]
    }
   ],
   "source": [
    "dropper = df[10:85]\n",
    "\n",
    "df = df.drop(dropper.index)\n",
    "\n",
    "for col in colies:\n",
    "    print(col, 'mean:', df[col].mean(), 'median:', df[col].median(), 'standard deviation:', df[col].std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Boston housing dataset\n",
    "\n",
    "You can use `from sklearn.datasets import load_boston` to load the boston housing dataset.\n",
    "\n",
    "The `load_boston()['DESCR']` will describe columns for you.\n",
    "\n",
    "Are any of the columns associated with per capita crime rate? If so, show the numeric relationship and give a possible explanation for highly correlated/negatively correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CRIM       1.000000\n",
       "ZN        -0.200469\n",
       "INDUS      0.406583\n",
       "CHAS      -0.055892\n",
       "NOX        0.420972\n",
       "RM        -0.219247\n",
       "AGE        0.352734\n",
       "DIS       -0.379670\n",
       "RAD        0.625505\n",
       "TAX        0.582764\n",
       "PTRATIO    0.289946\n",
       "B         -0.385064\n",
       "LSTAT      0.455621\n",
       "MEDV      -0.388305\n",
       "Name: CRIM, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(data=boston.data, columns=boston.feature_names)\n",
    "df['MEDV'] = boston.target\n",
    "\n",
    "df.corr()['CRIM']\n",
    "\n",
    "#It seems like the strongest correlation is between crime and accessibility to radial highways. It seems strange, but it is likely that noise from highways prevents luxury development, meaning that more impoverished and underserved neighbourhoods are near highways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Do any of the suburbs of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "73.9865781990693\n85.36267644268776\n28404.759488122727\n302.7628458498024\n4.686989120651195\n3.5444664031620334\n"
     ]
    }
   ],
   "source": [
    "#The method I will use is to comapre the variance of the variable against the maximum variable of the neighbourhood. If the differene is great, then we know that this neighbourhood is particularily high on the variable.\n",
    "\n",
    "print(stat.variance(df.CRIM))\n",
    "print(df.CRIM.max() - np.mean(df.CRIM))\n",
    "\n",
    "print(stat.variance(df.TAX))\n",
    "print(df.TAX.max() - np.mean(df.TAX))\n",
    "\n",
    "print(stat.variance(df.PTRATIO))\n",
    "print(df.PTRATIO.max() - np.mean(df.PTRATIO))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 How many of the suburbs in this data set bound the Charles river?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "df.CHAS.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 What is the median pupil-teacher ratio among the towns in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19.05"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "df.PTRATIO.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Which suburb of Boston has lowest median value of owneroccupied homes? What are the values of the other predictors for that suburb, and how do those values compare to the overall ranges for those predictors? Comment on your findings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        CRIM   ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n398  38.3518  0.0   18.1   0.0  0.693  5.453  100.0  1.4896  24.0  666.0   \n405  67.9208  0.0   18.1   0.0  0.693  5.683  100.0  1.4254  24.0  666.0   \n\n     PTRATIO       B  LSTAT  MEDV  \n398     20.2  396.90  30.59   5.0  \n405     20.2  384.97  22.98   5.0  \nCRIM         3.613524\nZN          11.363636\nINDUS       11.136779\nCHAS         0.069170\nNOX          0.554695\nRM           6.284634\nAGE         68.574901\nDIS          3.795043\nRAD          9.549407\nTAX        408.237154\nPTRATIO     18.455534\nB          356.674032\nLSTAT       12.653063\nMEDV        22.532806\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df.MEDV == df.MEDV.min()])\n",
    "\n",
    "#To compare, I will create a table of the averages of all categories in the Boston dataset.\n",
    "av_table = df.mean()\n",
    "print(av_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 In this data set, how many of the suburbs average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the suburbs that average more than eight rooms per dwelling.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The number of suburbs with greater than 7 rooms (on average): 64\nThe number of suburbs with greater than 8 rooms (on average): 13\nThe difference in average between 7 bedroom neighbourhoods and the average: CRIM        2.634415\nZN        -16.808239\nINDUS       5.361154\nCHAS       -0.055830\nNOX         0.050240\nRM         -1.285459\nAGE         7.934276\nDIS        -0.404574\nRAD         3.565032\nTAX        96.002779\nPTRATIO     2.196159\nB         -31.601125\nLSTAT       7.179001\nMEDV      -15.864069\ndtype: float64\nThe difference in average between 8 bedroom neighbourhoods and the average: CRIM        2.894728\nZN         -2.251748\nINDUS       4.058317\nCHAS       -0.084676\nNOX         0.015457\nRM         -2.063904\nAGE        -2.963560\nDIS         0.364850\nRAD         2.087869\nTAX        83.160231\nPTRATIO     2.093995\nB         -28.536738\nLSTAT       8.343063\nMEDV      -21.667194\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('The number of suburbs with greater than 7 rooms (on average):', sum(df.RM > 7))\n",
    "print('The number of suburbs with greater than 8 rooms (on average):', sum(df.RM > 8))\n",
    "#We can 'comment on' the features of these neighbourhoods by comparing them against the whole dataset. To do so, I will make a table which shows their difference (on average) against all of Boston.\n",
    "df2 = df.loc[df.RM > 7]\n",
    "df2 = df2.mean()\n",
    "df3 = df.loc[df.RM > 8]\n",
    "df3 = df3.mean()\n",
    "print('The difference in average between 7 bedroom neighbourhoods and the average:', av_table - df2)\n",
    "print('The difference in average between 8 bedroom neighbourhoods and the average:', av_table - df3)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}